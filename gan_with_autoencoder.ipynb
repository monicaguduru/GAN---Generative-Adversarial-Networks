{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_2_question_3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "8y3p_Jc-ckPb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler \n",
        "from torch.autograd import Variable\n",
        "from PIL import Image\n",
        "from torchvision.utils import save_image\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import argparse\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import math\n",
        "from glob import glob\n",
        "from google.colab import drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LXijnXSmdg4v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "noOfEpochs = 20\n",
        "input_image = (3, 200, 180)\n",
        "eeta = 0.001\n",
        "b1 = 0.5\n",
        "interval = 100\n",
        "batch_size = 32\n",
        "b2 = 0.999\n",
        "ldim = 200\n",
        "\n",
        "os.makedirs(\"images\", exist_ok=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KHwJJwXGdl1O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class autoEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(autoEncoder, self).__init__()\n",
        "\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(3*200*180,2000 ),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(2000, 1000),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(1000, 200),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(200, 100),   # compress to 3 features which can be visualized in plt\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(100, 200),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(200, 1000),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(1000, 2000),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(2000, 3*200*180),\n",
        "            nn.Sigmoid(),       # compress to a range (0, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return decoded\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(int(np.prod(input_image)), 256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        \n",
        "        img_flat = img.view(img.shape[0], -1)\n",
        "        legitity = self.model(img_flat)\n",
        "\n",
        "        return legitity"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mWwcHQ6hdtty",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6fd445cb-6a8e-4319-cc64-c9b1bc21204e"
      },
      "cell_type": "code",
      "source": [
        "drive.mount(\"/content/drive\")\n",
        "advLoss = torch.nn.BCELoss()\n",
        "autoEncoder = autoEncoder()\n",
        "discriminator = Discriminator()\n",
        "autoEncoder_optimizer = torch.optim.Adam(autoEncoder.parameters(), lr=eeta, betas=(b1, b2))\n",
        "discriminator_optimizer = torch.optim.Adam(discriminator.parameters(), lr=eeta, betas=(b1, b2))\n",
        "Tensor = torch.FloatTensor\n",
        "dir_path = 'drive/My Drive/faces94'\n",
        "files = glob(f\"{dir_path}/**/**/*.jpg\")\n",
        "c2i = {\n",
        "    \"female\": 0,\n",
        "    \"male\":1,\n",
        "    \"malestaff\": 2 \n",
        "}\n",
        "tloader = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5],[0.5])\n",
        "])\n",
        "\n",
        "total_dataset = torch.stack([tloader(Image.open(x)) for x in files])\n",
        "total_labels = torch.tensor([c2i[x.split('/')[-3]] for x in files])\n",
        "\n",
        "index_train, index_test = train_test_split(range(len(total_dataset)), test_size=0.2, random_state=102)\n",
        "\n",
        "train_image = total_dataset[index_train]\n",
        "train_label = total_labels[index_train]\n",
        "\n",
        "test_image = total_dataset[index_test]\n",
        "test_label = total_labels[index_test]\n",
        "\n",
        "train_data = TensorDataset(train_image, train_label)\n",
        "test_data = TensorDataset(test_image, test_label)\n",
        "\n",
        "train_sample = RandomSampler(train_data)\n",
        "test_sample = SequentialSampler(test_data)\n",
        "\n",
        "train_loader = DataLoader(train_data, sampler=train_sample, batch_size=32)\n",
        "test_loader = DataLoader(test_data, sampler=test_sample, batch_size=32)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aHwka9WSdzem",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for epoch in range(noOfEpochs):\n",
        "    for i, (images,_) in enumerate(train_loader):\n",
        "        legit = Variable(Tensor(images.size(0), 1).fill_(1.0), requires_grad=False)\n",
        "        fake_autoEncoder_images = Variable(Tensor(images.size(0), 1).fill_(0.0), requires_grad=False)\n",
        "\n",
        "        # Configure input\n",
        "        real_images = Variable(images.type(Tensor))\n",
        "        \n",
        "        #print(real_images)\n",
        "\n",
        "        autoEncoder_optimizer.zero_grad()\n",
        "        \n",
        "        # Sample noise as autoEncoder input\n",
        "        z = Variable(Tensor(np.random.normal(0, 1, (32,108000))))\n",
        "\n",
        "        # Generate a batch of images\n",
        "        autoEncoder_images = autoEncoder(z)\n",
        "        print(type(autoEncoder_images))\n",
        "        # Loss measures generator's ability to fool the discriminator\n",
        "        autoEncoder_loss = advLoss(discriminator(autoEncoder_images), legit)\n",
        "\n",
        "        autoEncoder_loss.backward()\n",
        "        autoEncoder_optimizer.step()\n",
        "\n",
        "        discriminator_optimizer.zero_grad()\n",
        "\n",
        "        # Measure discriminator's ability to classify real from autoEncoder samples\n",
        "        real_loss = advLoss(discriminator(real_images), legit)\n",
        "        autoEncoder_images_loss = advLoss(discriminator(autoEncoder_images.detach()), fake_autoEncoder_images)\n",
        "        discriminator_loss = (real_loss + autoEncoder_images_loss) / 2\n",
        "\n",
        "        discriminator_loss.backward()\n",
        "        discriminator_optimizer.step()\n",
        "\n",
        "        batches_done = epoch * len(train_loader) + i\n",
        "        if batches_done % interval == 0:\n",
        "            save_image(autoEncoder_images.data[:25], \"images/%d.png\" % batches_done, nrow=5, normalize=True)\n",
        "            \n",
        "        print(\"[Epoch = %d/%d] [Batch = %d/%d] [Discriminator loss = %f] [Generator loss = %f]\" % (epoch, noOfEpochs, i, len(train_loader), discriminator_loss.item(), autoEncoder_loss.item()))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zjWOgmp37xid",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}