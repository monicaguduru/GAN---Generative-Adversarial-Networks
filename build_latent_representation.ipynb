{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_2_question_2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "H02swUlvqO-u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "from glob import glob\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import csv\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as Data\n",
        "from matplotlib import cm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iD7E748slbbS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "74c78eb2-2fa5-4830-a8fa-8038398c5a2f"
      },
      "cell_type": "code",
      "source": [
        "drive.mount(\"/content/drive\")\n",
        "path = 'drive/My Drive/faces94' \n",
        "files = glob(f\"{path}/**/**/*.jpg\")\n",
        "c2i = {\n",
        "    \"female\": 0,\n",
        "    \"male\":1,\n",
        "    \"malestaff\": 2 \n",
        "}\n",
        "\n",
        "c_files = files #[:50]\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform_loader = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5],[0.5])\n",
        "])\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "G4S1b734p8hS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "total_images = torch.stack([transform_loader(Image.open(x)) for x in c_files])\n",
        "total_labels = torch.tensor([c2i[x.split('/')[-3]] for x in c_files])\n",
        "\n",
        "index_train, index_test = train_test_split(range(len(total_images)), test_size=0.2, random_state=102)\n",
        "\n",
        "train_image = total_images[index_train]\n",
        "train_label = total_labels[index_train]\n",
        "\n",
        "test_image = total_images[index_test]\n",
        "test_label = total_labels[index_test]\n",
        "\n",
        "noOfEpochs = 10\n",
        "size_of_batch = 64\n",
        "eeta = 0.005         \n",
        "dataset_download = True\n",
        "test_images_count = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fIdB5Y-pqApf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class autoEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(autoEncoder, self).__init__()\n",
        "\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(3*200*180,2000 ),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(2000, 1000),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(1000, 200),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(200, 100),   # compress to 3 features which can be visualized in plt\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(100, 200),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(200, 1000),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(1000, 2000),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(2000, 3*200*180),\n",
        "            nn.Sigmoid(),       # compress to a range (0, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return encoded, decoded"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QkkdwWrIqEH_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "b7232904-4f65-4cb4-be25-85a4c096986d"
      },
      "cell_type": "code",
      "source": [
        "autoEncoder = autoEncoder()\n",
        "\n",
        "optimizer = torch.optim.Adam(autoEncoder.parameters(), lr=eeta)\n",
        "loss_function = nn.MSELoss()\n",
        "\n",
        "output_file = open('output.csv', 'w')\n",
        "outputList = []\n",
        "print(train_label[0])\n",
        "for noOfEpochs in range(noOfEpochs):\n",
        "    for step,x in enumerate(train_image):\n",
        "        b_x = x.view(-1, 3*200*180)   # batch x, shape (batch, 28*28)\n",
        "        b_y = x.view(-1, 3*200*180)   # batch y, shape (batch, 28*28)\n",
        "        encoded, decoded = autoEncoder(b_x)\n",
        "        li = []\n",
        "        \n",
        "        li = encoded.detach().numpy().tolist();\n",
        "        li = li[0]\n",
        "        print(li)\n",
        "        outputList.append(li); #appending encoded image\n",
        "        outputList.append(train_label[step])\n",
        "        loss = loss_function(decoded, b_y)      # mean square error\n",
        "        optimizer.zero_grad()               # clear gradients for this training step\n",
        "        loss.backward()                     # backpropagation, compute gradients\n",
        "        optimizer.step()                    # apply gradients\n",
        "\n",
        "        if step % 100 == 0:\n",
        "            print('noOfEpochs: ', noOfEpochs, '| train loss: %.4f' % loss.data.numpy())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1)\n",
            "[0.04861484467983246, -0.0669759064912796, 0.03922516852617264, 0.05992425978183746, 0.17433378100395203, -0.06788696348667145, 0.08884594589471817, -0.1075010746717453, 0.02321121096611023, 0.06106927618384361, 0.02039877511560917, 0.05212844908237457, -0.07981979101896286, -0.015615101903676987, -0.08645591884851456, -0.0011903494596481323, 0.005055472254753113, 0.02937234193086624, 0.040755800902843475, 0.0618453212082386, 0.007154615595936775, -0.047085341066122055, 0.031027331948280334, -0.06998149305582047, 0.07431747764348984, -0.07101485133171082, -0.09123602509498596, 0.01496167853474617, -0.04091088846325874, 0.03091440349817276, 0.013181682676076889, -0.05238592252135277, 0.17508038878440857, -0.0695321336388588, -0.045423295348882675, 0.02126821130514145, -0.06020013615489006, -0.013040106743574142, 0.017989035695791245, -0.0583009198307991, -0.10448411107063293, -0.1308140605688095, -0.07537677139043808, 0.030501432716846466, 0.1321784257888794, 0.09697340428829193, -0.02100571244955063, -0.04179329425096512, -0.0076024942100048065, -0.14651304483413696, -0.06485121697187424, 0.061563968658447266, 0.02915225364267826, 0.095940001308918, 0.17130976915359497, -0.07124778628349304, -0.033120833337306976, 0.04503090679645538, 0.1566726565361023, 0.021606646478176117, 0.05250716954469681, 0.08096519112586975, -0.12747114896774292, -0.010174451395869255, 0.06791787594556808, 0.05538397282361984, -0.004172675311565399, -0.010989591479301453, -0.07892332971096039, -0.010050497949123383, 0.08959045261144638, -0.004088174551725388, -0.06461337953805923, 0.1136813759803772, 0.10432695597410202, 0.029648341238498688, 0.0832819938659668, -0.06151054799556732, -0.07091003656387329, -0.0811774730682373, 0.10536590218544006, 0.05861953645944595, -0.05984703451395035, 0.10736338049173355, -0.08445673435926437, 0.04421554505825043, 0.14955317974090576, 0.06798499077558517, 0.07112981379032135, 0.10276035964488983, -0.03312177583575249, -0.09286724030971527, -0.12622147798538208, -0.06893090903759003, -0.10538758337497711, -0.07244710624217987, -0.04373832046985626, -0.09033602476119995, -0.030326148495078087, -0.0665988177061081]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SLjJ1eH5qHWQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with output_file:\n",
        "    writer = csv.writer(output_file)\n",
        "    writer.writerows(outputList)\n",
        "\n",
        "\n",
        "for step,x in enumerate(noOfEpochs):\n",
        "    b_x = x.view(-1, 3*200*180)   # batch x, shape (batch, 28*28)\n",
        "    b_y = x.view(-1, 3*200*180)   # batch y, shape (batch, 28*28)\n",
        "    #print(b_x)\n",
        "    encoded, decoded = autoEncoder(b_x)\n",
        "\n",
        "    loss = loss_function(decoded, b_y)      # mean square error\n",
        "\n",
        "    if step % 100 == 0:\n",
        "        print('noOfEpochs: ', noOfEpochs, '| test loss: %.4f' % loss.data.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}